{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CSI 4142 Data Science** <br/>\n",
    "*Assignment 3: Predictive Analysis and Classification*\n",
    "\n",
    "# Identification\n",
    "\n",
    "Name: Eli Wynn<br/>\n",
    "Student Number: 300248135\n",
    "\n",
    "Name: Jack Snelgrove<br/>\n",
    "Student Number: 300247435\n",
    "\n",
    "\n",
    "Our datasets have been uploaded from the public repository:\n",
    "\n",
    "- [github.com/eli-wynn/Datasets](https://github.com/eli-wynn/Datasets)\n",
    "\n",
    "# Running Instructions\n",
    "1. Generate a kaggle Api key on the kaggle website under your Account < Settings < Generate Key\n",
    "2. This will generate a kaggle.json file\n",
    "3. Place the file in its respective location\n",
    "- On Windows: place the file here C:\\Users\\<YourUsername>\\.kaggle\\kaggle.json\n",
    "- On Mac: place the file here: ~/.kaggle/kaggle.json\n",
    "\n",
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#configure database -> can't use github because files are too large\n",
    "#!pip install kaggle\n",
    "#!pip install python-Levenshtein\n",
    "#Run the above lines if library has not been previously installed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import kaggle\n",
    "import Levenshtein\n",
    "import re\n",
    "import ast\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/rounakbanik/the-movies-dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eliwy\\AppData\\Local\\Temp\\ipykernel_27492\\1111194188.py:16: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  metadataDF = pd.read_csv(f\"{download_path}/movies_metadata.csv\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1425941529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>147</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1425942435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>858</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1425941523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1221</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1425941546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1246</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1425941556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating   timestamp\n",
       "0       1      110     1.0  1425941529\n",
       "1       1      147     4.5  1425942435\n",
       "2       1      858     5.0  1425941523\n",
       "3       1     1221     5.0  1425941546\n",
       "4       1     1246     5.0  1425941556"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "import os\n",
    "import kaggle\n",
    "\n",
    "# Set environment variables\n",
    "os.environ[\"KAGGLE_USERNAME\"] = \"eliwynn\"\n",
    "os.environ[\"KAGGLE_KEY\"] = \"c71d95504bba7ec81de8ed35ec02b166\"\n",
    "\n",
    "# Download the dataset\n",
    "dataset = \"rounakbanik/the-movies-dataset\"\n",
    "download_path = \"./movies_dataset\"\n",
    "\n",
    "#download entire dataset\n",
    "kaggle.api.dataset_download_files(dataset, download_path, unzip=True)\n",
    "\n",
    "metadataDF = pd.read_csv(f\"{download_path}/movies_metadata.csv\")\n",
    "metadataDF.head()\n",
    "ratingsDF = pd.read_csv(f\"{download_path}/ratings.csv\")\n",
    "ratingsDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Dataset Description**\n",
    "\n",
    "## **Overview**\n",
    "| Attribute | Description |\n",
    "|-----------|-------------|\n",
    "| Dataset Name | The Movies Dataset |\n",
    "| Author | Rounak Banik |\n",
    "| Purpose | Provides metadata and ratings for movies to facilitate film analysis and recommendation system development |\n",
    "| Shape | 45,466 rows × 24 columns (movies metadata), 100,004 rows × 4 columns (ratings) |\n",
    "\n",
    "## **Features**\n",
    "\n",
    "### **Movies Metadata (`movies_metadata.csv`)**\n",
    "| Feature Name | Type | Description |\n",
    "|-------------|------|-------------|\n",
    "| id | Categorical | Unique identifier for each movie |\n",
    "| title | Categorical | Title of the movie |\n",
    "| release_date | DateTime | Release date of the movie |\n",
    "| budget | Numerical | Production budget in USD |\n",
    "| revenue | Numerical | Box office revenue in USD |\n",
    "| genres | Categorical | List of genres associated with the movie |\n",
    "| popularity | Numerical | Popularity score based on TMDb metrics |\n",
    "| vote_average | Numerical | Average user rating (0-10) |\n",
    "| vote_count | Numerical | Total number of votes received |\n",
    "| production_companies | Categorical | List of companies that produced the movie |\n",
    "| production_countries | Categorical | Countries where the movie was produced |\n",
    "| runtime | Numerical | Duration of the movie in minutes |\n",
    "| spoken_languages | Categorical | List of languages spoken in the movie |\n",
    "\n",
    "### **Ratings (`ratings_small.csv`)**\n",
    "| Feature Name | Type | Description |\n",
    "|-------------|------|-------------|\n",
    "| userId | Categorical | Unique identifier for each user |\n",
    "| movieId | Categorical | Unique identifier for each movie (links to `id` in movies metadata) |\n",
    "| rating | Numerical | User rating of the movie (0.5 - 5.0) |\n",
    "| timestamp | DateTime | Unix timestamp of when the rating was given |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_movie_datasets():\n",
    "    \"\"\"\n",
    "    Prepare the movie datasets (movies_metadata.csv and ratings_small.csv)\n",
    "    \"\"\"\n",
    "\n",
    "    metadataDF = pd.read_csv('./movies_dataset/movies_metadata.csv', low_memory=False)\n",
    "    ratingsDF = pd.read_csv('./movies_dataset/ratings_small.csv')\n",
    "    \n",
    "    # Display basic information\n",
    "    print(\"Movies Metadata Shape:\", metadataDF.shape)\n",
    "    print(\"Ratings Shape:\", ratingsDF.shape)\n",
    "    \n",
    "    # Clean the movies dataset\n",
    "    print(\"Cleaning movies dataset...\")\n",
    "    \n",
    "    # Convert 'id' to numeric, coercing errors to NaN\n",
    "    metadataDF['id'] = pd.to_numeric(metadataDF['id'], errors='coerce')\n",
    "    \n",
    "    # Drop rows with NaN in 'id'\n",
    "    metadataDF = metadataDF.dropna(subset=['id'])\n",
    "    \n",
    "    # Convert 'id' to integer\n",
    "    metadataDF['id'] = metadataDF['id'].astype(int)\n",
    "    \n",
    "    # Select relevant columns\n",
    "    metadataDF = metadataDF[['id', 'title', 'release_date', 'popularity', 'vote_average', 'vote_count', 'budget', 'revenue', 'runtime', 'genres', 'overview']]\n",
    "    \n",
    "    # Convert date column to datetime\n",
    "    metadataDF['release_date'] = pd.to_datetime(metadataDF['release_date'], errors='coerce')\n",
    "    \n",
    "    # Extract year from release_date\n",
    "    metadataDF['release_year'] = metadataDF['release_date'].dt.year\n",
    "    \n",
    "    # Drop rows with missing values in important columns\n",
    "    metadataDF = metadataDF.dropna(subset=['release_year', 'popularity', 'vote_average', 'vote_count'])\n",
    "    \n",
    "    # Convert numeric columns to appropriate types\n",
    "    numeric_cols = ['popularity', 'vote_average', 'vote_count', 'budget', 'revenue', 'runtime']\n",
    "    for col in numeric_cols:\n",
    "        metadataDF[col] = pd.to_numeric(metadataDF[col], errors='coerce')\n",
    "    \n",
    "    # Fill missing values with median\n",
    "    for col in numeric_cols:\n",
    "        metadataDF[col] = metadataDF[col].fillna(metadataDF[col].median())\n",
    "    \n",
    "    # Prepare the ratings dataset\n",
    "    print(\"Preparing ratings dataset...\")\n",
    "    \n",
    "    # Rename movieId to match with metadataDF id\n",
    "    ratingsDF = ratingsDF.rename(columns={'movieId': 'id'})\n",
    "    \n",
    "    # Merge datasets\n",
    "    print(\"Merging datasets...\")\n",
    "    merged_df = pd.merge(ratingsDF, metadataDF, on='id', how='inner')\n",
    "    \n",
    "    print(\"Merged dataset shape:\", merged_df.shape)\n",
    "    \n",
    "    # Create features and target\n",
    "    # Target: High rating (1 if rating >= 4.0, 0 otherwise)\n",
    "    merged_df['high_rating'] = (merged_df['rating'] >= 4.0).astype(int)\n",
    "    \n",
    "    # Features: movie attributes\n",
    "    features = ['popularity', 'vote_average', 'vote_count', 'budget', 'revenue', 'runtime', 'release_year']\n",
    "    X = merged_df[features]\n",
    "    y = merged_df['high_rating']\n",
    "    \n",
    "    # Split into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    print(\"Movie datasets prepared successfully!\")\n",
    "    return X_train_scaled, X_test_scaled, y_train, y_test, merged_df, metadataDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Study 1: Similarity Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies Metadata Shape: (45466, 24)\n",
      "Ratings Shape: (100004, 4)\n",
      "Cleaning movies dataset...\n",
      "Preparing ratings dataset...\n",
      "Merging datasets...\n",
      "Merged dataset shape: (44965, 15)\n",
      "Movie datasets prepared successfully!\n",
      "Preparing data for similarity measures...\n",
      "\n",
      "=== Study 1 – Similarity Measures ===\n",
      "\n",
      "Request 1: Show me movies of the same genre as 'Toy Story'\n",
      "\n",
      "--- Top 10 movies with similar genres to 'Toy Story' ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Similarity</th>\n",
       "      <th>Genres</th>\n",
       "      <th>Popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Emoji Movie</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>[Comedy, Family, Animation]</td>\n",
       "      <td>33.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Monsters, Inc.</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>[Animation, Comedy, Family]</td>\n",
       "      <td>26.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Despicable Me 2</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>[Animation, Comedy, Family]</td>\n",
       "      <td>24.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chicken Little</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>[Animation, Family, Comedy]</td>\n",
       "      <td>18.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Toy Story 2</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>[Animation, Comedy, Family]</td>\n",
       "      <td>17.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Toy Story 3</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>[Animation, Family, Comedy]</td>\n",
       "      <td>16.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Cloudy with a Chance of Meatballs 2</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>[Animation, Family, Comedy]</td>\n",
       "      <td>14.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Simpsons Movie</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>[Animation, Comedy, Family]</td>\n",
       "      <td>14.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Looney Tunes: Back in Action</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>[Animation, Comedy, Family]</td>\n",
       "      <td>13.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Boss Baby</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>[Animation, Comedy, Family]</td>\n",
       "      <td>13.39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Title Similarity  \\\n",
       "0                      The Emoji Movie     1.0000   \n",
       "1                       Monsters, Inc.     1.0000   \n",
       "2                      Despicable Me 2     1.0000   \n",
       "3                       Chicken Little     1.0000   \n",
       "4                          Toy Story 2     1.0000   \n",
       "5                          Toy Story 3     1.0000   \n",
       "6  Cloudy with a Chance of Meatballs 2     1.0000   \n",
       "7                   The Simpsons Movie     1.0000   \n",
       "8         Looney Tunes: Back in Action     1.0000   \n",
       "9                        The Boss Baby     1.0000   \n",
       "\n",
       "                        Genres Popularity  \n",
       "0  [Comedy, Family, Animation]      33.69  \n",
       "1  [Animation, Comedy, Family]      26.42  \n",
       "2  [Animation, Comedy, Family]      24.82  \n",
       "3  [Animation, Family, Comedy]      18.58  \n",
       "4  [Animation, Comedy, Family]      17.55  \n",
       "5  [Animation, Family, Comedy]      16.97  \n",
       "6  [Animation, Family, Comedy]      14.41  \n",
       "7  [Animation, Comedy, Family]      14.30  \n",
       "8  [Animation, Comedy, Family]      13.67  \n",
       "9  [Animation, Comedy, Family]      13.39  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Request 2: Show me movies with similar revenue to 'Titanic'\n",
      "\n",
      "--- Top 10 movies with similar revenue to 'Titanic' ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Similarity</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>Popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Star Wars: The Force Awakens</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>2.068224e+09</td>\n",
       "      <td>31.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Avengers</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>1.519558e+09</td>\n",
       "      <td>89.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jurassic World</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>1.513529e+09</td>\n",
       "      <td>32.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Furious 7</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>1.506249e+09</td>\n",
       "      <td>27.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Avengers: Age of Ultron</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>1.405404e+09</td>\n",
       "      <td>37.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Harry Potter and the Deathly Hallows: Part 2</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>1.342000e+09</td>\n",
       "      <td>24.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Frozen</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>1.274219e+09</td>\n",
       "      <td>24.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Beauty and the Beast</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>1.262886e+09</td>\n",
       "      <td>287.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The Fate of the Furious</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>1.238765e+09</td>\n",
       "      <td>48.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Iron Man 3</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>1.215440e+09</td>\n",
       "      <td>23.72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Title Similarity       Revenue  \\\n",
       "0                  Star Wars: The Force Awakens     0.0045  2.068224e+09   \n",
       "1                                  The Avengers     0.0031  1.519558e+09   \n",
       "2                                Jurassic World     0.0030  1.513529e+09   \n",
       "3                                     Furious 7     0.0029  1.506249e+09   \n",
       "4                       Avengers: Age of Ultron     0.0023  1.405404e+09   \n",
       "5  Harry Potter and the Deathly Hallows: Part 2     0.0020  1.342000e+09   \n",
       "6                                        Frozen     0.0017  1.274219e+09   \n",
       "7                          Beauty and the Beast     0.0017  1.262886e+09   \n",
       "8                       The Fate of the Furious     0.0016  1.238765e+09   \n",
       "9                                    Iron Man 3     0.0016  1.215440e+09   \n",
       "\n",
       "  Popularity  \n",
       "0      31.63  \n",
       "1      89.89  \n",
       "2      32.79  \n",
       "3      27.28  \n",
       "4      37.38  \n",
       "5      24.99  \n",
       "6      24.25  \n",
       "7     287.25  \n",
       "8      48.57  \n",
       "9      23.72  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Request 3: Show me movies with similar length as 'Apollo 13'\n",
      "\n",
      "--- Top 10 movies with similar runtime (minutes) to 'Apollo 13' ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Similarity</th>\n",
       "      <th>Runtime (minutes)</th>\n",
       "      <th>Popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>War for the Planet of the Apes</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>140.0</td>\n",
       "      <td>146.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Operation Mekong</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>140.0</td>\n",
       "      <td>35.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Batman Begins</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>140.0</td>\n",
       "      <td>28.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Lost City of Z</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>140.0</td>\n",
       "      <td>21.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hacksaw Ridge</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>140.0</td>\n",
       "      <td>21.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Star Wars: Episode III - Revenge of the Sith</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>140.0</td>\n",
       "      <td>13.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Warrior</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>140.0</td>\n",
       "      <td>13.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>La Vie en Rose</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>140.0</td>\n",
       "      <td>11.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The Karate Kid</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>140.0</td>\n",
       "      <td>11.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Death on the Nile</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>140.0</td>\n",
       "      <td>11.16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Title Similarity  Runtime (minutes)  \\\n",
       "0                War for the Planet of the Apes     1.0000              140.0   \n",
       "1                              Operation Mekong     1.0000              140.0   \n",
       "2                                 Batman Begins     1.0000              140.0   \n",
       "3                            The Lost City of Z     1.0000              140.0   \n",
       "4                                 Hacksaw Ridge     1.0000              140.0   \n",
       "5  Star Wars: Episode III - Revenge of the Sith     1.0000              140.0   \n",
       "6                                       Warrior     1.0000              140.0   \n",
       "7                                La Vie en Rose     1.0000              140.0   \n",
       "8                                The Karate Kid     1.0000              140.0   \n",
       "9                             Death on the Nile     1.0000              140.0   \n",
       "\n",
       "  Popularity  \n",
       "0     146.16  \n",
       "1      35.97  \n",
       "2      28.51  \n",
       "3      21.79  \n",
       "4      21.04  \n",
       "5      13.17  \n",
       "6      13.12  \n",
       "7      11.71  \n",
       "8      11.69  \n",
       "9      11.16  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Request 4: Show me movies with similar title to 'Fight Club'\n",
      "\n",
      "--- Top 10 movies with similar title to 'Fight Club' ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Similarity</th>\n",
       "      <th>Popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0.6364</td>\n",
       "      <td>5.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0.6364</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>3.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.5882</td>\n",
       "      <td>3.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>0.5455</td>\n",
       "      <td>13.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>0.5455</td>\n",
       "      <td>5.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>0.5455</td>\n",
       "      <td>5.27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Title Similarity Popularity\n",
       "0      4     0.6364       5.42\n",
       "1      4     0.6364       0.14\n",
       "2      4     0.6000       3.53\n",
       "3      4     0.6000       0.57\n",
       "4      4     0.6000       0.48\n",
       "5      4     0.6000       0.44\n",
       "6      7     0.5882       3.80\n",
       "7      5     0.5455      13.88\n",
       "8      5     0.5455       5.56\n",
       "9      5     0.5455       5.27"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Request 5: Show me movies with similar budget to 'The Matrix'\n",
      "\n",
      "--- Top 10 movies with similar budget to 'The Matrix' ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Similarity</th>\n",
       "      <th>Budget</th>\n",
       "      <th>Popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Minions</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>74000000</td>\n",
       "      <td>547.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wonder Woman</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>149000000</td>\n",
       "      <td>294.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Beauty and the Beast</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>160000000</td>\n",
       "      <td>287.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Baby Driver</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>34000000</td>\n",
       "      <td>228.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Big Hero 6</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>165000000</td>\n",
       "      <td>213.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Deadpool</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>58000000</td>\n",
       "      <td>187.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Guardians of the Galaxy Vol. 2</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>200000000</td>\n",
       "      <td>185.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Avatar</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>237000000</td>\n",
       "      <td>185.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>John Wick</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>20000000</td>\n",
       "      <td>183.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Gone Girl</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>61000000</td>\n",
       "      <td>154.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Title Similarity     Budget Popularity\n",
       "0                         Minions     1.0000   74000000     547.49\n",
       "1                    Wonder Woman     1.0000  149000000     294.34\n",
       "2            Beauty and the Beast     1.0000  160000000     287.25\n",
       "3                     Baby Driver     1.0000   34000000     228.03\n",
       "4                      Big Hero 6     1.0000  165000000     213.85\n",
       "5                        Deadpool     1.0000   58000000     187.86\n",
       "6  Guardians of the Galaxy Vol. 2     1.0000  200000000     185.33\n",
       "7                          Avatar     1.0000  237000000     185.07\n",
       "8                       John Wick     1.0000   20000000     183.87\n",
       "9                       Gone Girl     1.0000   61000000     154.80"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, merged_df, metadataDF = prepare_movie_datasets()\n",
    "\n",
    "# Helper functions for processing movie data\n",
    "def extract_genres(genres_json):\n",
    "    \"\"\"Extract genre names from the JSON string in the genres column\"\"\"\n",
    "    try:\n",
    "        if isinstance(genres_json, str):\n",
    "            genres = ast.literal_eval(genres_json)\n",
    "            return [genre['name'] for genre in genres]\n",
    "        else:\n",
    "            return []\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "def clean_title(title):\n",
    "    \"\"\"Clean title for better similarity matching\"\"\"\n",
    "    if pd.isna(title):\n",
    "        return \"\"\n",
    "    # Remove special characters and convert to lowercase\n",
    "    return re.sub(r'[^\\w\\s]', '', title).lower()\n",
    "\n",
    "def extract_keywords(overview):\n",
    "    \"\"\"Extract keywords from overview text\"\"\"\n",
    "    if pd.isna(overview):\n",
    "        return \"\"\n",
    "    # Simple keyword extraction - remove stopwords and keep only words with 4+ characters\n",
    "    words = re.findall(r'\\b\\w{4,}\\b', overview.lower())\n",
    "    # Remove common stopwords\n",
    "    stopwords = ['this', 'that', 'with', 'from', 'have', 'they', 'will', 'what', 'when', 'where', 'which']\n",
    "    return ' '.join([w for w in words if w not in stopwords])\n",
    "\n",
    "# Prepare additional features for similarity measures\n",
    "print(\"Preparing data for similarity measures...\")\n",
    "metadataDF['genres_list'] = metadataDF['genres'].apply(extract_genres)\n",
    "metadataDF['clean_title'] = metadataDF['title'].apply(clean_title)\n",
    "metadataDF['keywords'] = metadataDF['overview'].apply(extract_keywords)\n",
    "\n",
    "# 1. Jaccard Similarity for Genres\n",
    "def jaccard_similarity_genres(movie_data, movie_title):\n",
    "    \"\"\"\n",
    "    Jaccard similarity for genres\n",
    "    Jaccard(A,B) = |A ∩ B| / |A ∪ B|\n",
    "    \"\"\"\n",
    "    # Find the movie by title\n",
    "    movie = movie_data[movie_data['title'] == movie_title]\n",
    "    if len(movie) == 0:\n",
    "        print(f\"Movie '{movie_title}' not found. Please check the title.\")\n",
    "        return []\n",
    "    \n",
    "    movie = movie.iloc[0]\n",
    "    movie_genres = set(movie['genres_list'])\n",
    "    \n",
    "    # Calculate Jaccard similarity for all movies\n",
    "    similarities = []\n",
    "    for idx, row in movie_data.iterrows():\n",
    "        other_genres = set(row['genres_list'])\n",
    "        if not movie_genres or not other_genres:\n",
    "            sim = 0\n",
    "        else:\n",
    "            intersection = len(movie_genres.intersection(other_genres))\n",
    "            union = len(movie_genres.union(other_genres))\n",
    "            sim = intersection / union if union > 0 else 0\n",
    "        similarities.append((row['title'], sim, row['genres_list'], row['popularity']))\n",
    "    \n",
    "    # Sort by similarity (descending) and then by popularity (descending)\n",
    "    return sorted(similarities, key=lambda x: (-x[1], -x[3]))\n",
    "\n",
    "# 2. Euclidean Similarity for Revenue\n",
    "def euclidean_similarity_revenue(movie_data, movie_title):\n",
    "    \"\"\"\n",
    "    Euclidean distance for revenue\n",
    "    Converted to similarity: 1 / (1 + distance)\n",
    "    \"\"\"\n",
    "    # Find the movie by title\n",
    "    movie = movie_data[movie_data['title'] == movie_title]\n",
    "    if len(movie) == 0:\n",
    "        print(f\"Movie '{movie_title}' not found. Please check the title.\")\n",
    "        return []\n",
    "    \n",
    "    movie = movie.iloc[0]\n",
    "    movie_revenue = movie['revenue']\n",
    "    \n",
    "    # Calculate Euclidean similarity for all movies\n",
    "    similarities = []\n",
    "    for idx, row in movie_data.iterrows():\n",
    "        other_revenue = row['revenue']\n",
    "        # Calculate Euclidean distance\n",
    "        distance = abs(movie_revenue - other_revenue)\n",
    "        # Convert to similarity (higher is more similar)\n",
    "        sim = 1 / (1 + distance/1e6)  # Normalize by dividing by 1 million\n",
    "        similarities.append((row['title'], sim, row['revenue'], row['popularity']))\n",
    "    \n",
    "    # Sort by similarity (descending) and then by popularity (descending)\n",
    "    return sorted(similarities, key=lambda x: (-x[1], -x[3]))\n",
    "\n",
    "# 3. Manhattan Similarity for Runtime\n",
    "def manhattan_similarity_runtime(movie_data, movie_title):\n",
    "    \"\"\"\n",
    "    Manhattan distance for runtime\n",
    "    Converted to similarity: 1 / (1 + distance)\n",
    "    \"\"\"\n",
    "    # Find the movie by title\n",
    "    movie = movie_data[movie_data['title'] == movie_title]\n",
    "    if len(movie) == 0:\n",
    "        print(f\"Movie '{movie_title}' not found. Please check the title.\")\n",
    "        return []\n",
    "    \n",
    "    movie = movie.iloc[0]\n",
    "    movie_runtime = movie['runtime']\n",
    "    \n",
    "    # Calculate Manhattan similarity for all movies\n",
    "    similarities = []\n",
    "    for idx, row in movie_data.iterrows():\n",
    "        other_runtime = row['runtime']\n",
    "        # Calculate Manhattan distance\n",
    "        distance = abs(movie_runtime - other_runtime)\n",
    "        # Convert to similarity (higher is more similar)\n",
    "        sim = 1 / (1 + distance/10)  # Normalize by dividing by 10\n",
    "        similarities.append((row['title'], sim, row['runtime'], row['popularity']))\n",
    "    \n",
    "    # Sort by similarity (descending) and then by popularity (descending)\n",
    "    return sorted(similarities, key=lambda x: (-x[1], -x[3]))\n",
    "\n",
    "# 4. Levenshtein (Edit Distance) Similarity for Title\n",
    "def levenshtein_similarity_title(movie_data, movie_title):\n",
    "    \"\"\"\n",
    "    Levenshtein (edit) distance for titles\n",
    "    Converted to similarity: 1 - (distance / max_length)\n",
    "    \"\"\"\n",
    "    # Find the movie by title\n",
    "    movie = movie_data[movie_data['title'] == movie_title]\n",
    "    if len(movie) == 0:\n",
    "        print(f\"Movie '{movie_title}' not found. Please check the title.\")\n",
    "        return []\n",
    "    \n",
    "    movie = movie.iloc[0]\n",
    "    movie_clean_title = movie['clean_title']\n",
    "    \n",
    "    # Calculate Levenshtein similarity for all movies\n",
    "    similarities = []\n",
    "    for idx, row in movie_data.iterrows():\n",
    "        other_clean_title = row['clean_title']\n",
    "        # Calculate Levenshtein distance\n",
    "        distance = Levenshtein.distance(movie_clean_title, other_clean_title)\n",
    "        # Convert to similarity (higher is more similar)\n",
    "        max_len = max(len(movie_clean_title), len(other_clean_title))\n",
    "        sim = 1 - (distance / max_len) if max_len > 0 else 0\n",
    "        similarities.append((row['title'], sim, distance, row['popularity']))\n",
    "    \n",
    "    # Sort by similarity (descending) and then by popularity (descending)\n",
    "    return sorted(similarities, key=lambda x: (-x[1], -x[3]))\n",
    "\n",
    "# 5. Cosine Similarity for Budget\n",
    "def cosine_similarity_budget(movie_data, movie_title):\n",
    "    \"\"\"\n",
    "    Cosine similarity for budget\n",
    "    \"\"\"\n",
    "    # Find the movie by title\n",
    "    movie = movie_data[movie_data['title'] == movie_title]\n",
    "    if len(movie) == 0:\n",
    "        print(f\"Movie '{movie_title}' not found. Please check the title.\")\n",
    "        return []\n",
    "    \n",
    "    movie = movie.iloc[0]\n",
    "    movie_budget = movie['budget']\n",
    "    \n",
    "    # Calculate Cosine similarity for all movies\n",
    "    similarities = []\n",
    "    for idx, row in movie_data.iterrows():\n",
    "        other_budget = row['budget']\n",
    "        # Calculate Cosine similarity\n",
    "        if movie_budget == 0 and other_budget == 0:\n",
    "            sim = 1  # Both budgets are 0, consider them similar\n",
    "        elif movie_budget == 0 or other_budget == 0:\n",
    "            sim = 0  # One budget is 0, the other isn't\n",
    "        else:\n",
    "            # Cosine similarity for 1D is just the dot product divided by magnitudes\n",
    "            sim = (movie_budget * other_budget) / (abs(movie_budget) * abs(other_budget))\n",
    "        similarities.append((row['title'], sim, row['budget'], row['popularity']))\n",
    "    \n",
    "    # Sort by similarity (descending) and then by popularity (descending)\n",
    "    return sorted(similarities, key=lambda x: (-x[1], -x[3]))\n",
    "\n",
    "def display_results(results, title, attribute_name, top_n=10):\n",
    "    \"\"\"Display the top N results in a formatted way\"\"\"\n",
    "    print(f\"\\n--- Top {top_n} movies with similar {attribute_name} to '{title}' ---\")\n",
    "    \n",
    "    # Create a DataFrame for better display in notebook\n",
    "    result_df = pd.DataFrame([\n",
    "        {\n",
    "            'Title': movie_title,\n",
    "            'Similarity': f\"{similarity:.4f}\",\n",
    "            f'{attribute_name.capitalize()}': attribute,\n",
    "            'Popularity': f\"{popularity:.2f}\"\n",
    "        }\n",
    "        for movie_title, similarity, attribute, popularity in results[:top_n+1]\n",
    "        if movie_title != title  # Skip the query movie itself\n",
    "    ][:top_n])\n",
    "    \n",
    "    display(result_df)\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "# Run the similarity study\n",
    "print(\"\\n=== Study 1 – Similarity Measures ===\")\n",
    "\n",
    "# Define query movies\n",
    "toy_story = \"Toy Story\"\n",
    "titanic = \"Titanic\"\n",
    "apollo_13 = \"Apollo 13\"\n",
    "fight_club = \"Fight Club\"\n",
    "matrix = \"The Matrix\"\n",
    "\n",
    "# Verify movies exist in the dataset\n",
    "for movie in [toy_story, titanic, apollo_13, fight_club, matrix]:\n",
    "    if movie not in metadataDF['title'].values:\n",
    "        print(f\"Warning: '{movie}' not found in dataset. Using a similar title.\")\n",
    "        # Find closest match\n",
    "        closest = metadataDF.iloc[metadataDF['title'].apply(\n",
    "            lambda x: Levenshtein.distance(str(x).lower(), movie.lower())).argmin()]['title']\n",
    "        print(f\"Using '{closest}' instead of '{movie}'\")\n",
    "        if movie == toy_story:\n",
    "            toy_story = closest\n",
    "        elif movie == titanic:\n",
    "            titanic = closest\n",
    "        elif movie == apollo_13:\n",
    "            apollo_13 = closest\n",
    "        elif movie == fight_club:\n",
    "            fight_club = closest\n",
    "        elif movie == matrix:\n",
    "            matrix = closest\n",
    "\n",
    "# 1. Jaccard similarity for genres\n",
    "print(\"\\nRequest 1: Show me movies of the same genre as 'Toy Story'\")\n",
    "genre_results = jaccard_similarity_genres(metadataDF, toy_story)\n",
    "genre_df = display_results(genre_results, toy_story, \"genres\")\n",
    "\n",
    "# 2. Euclidean similarity for revenue\n",
    "print(\"\\nRequest 2: Show me movies with similar revenue to 'Titanic'\")\n",
    "revenue_results = euclidean_similarity_revenue(metadataDF, titanic)\n",
    "revenue_df = display_results(revenue_results, titanic, \"revenue\")\n",
    "\n",
    "# 3. Manhattan similarity for runtime\n",
    "print(\"\\nRequest 3: Show me movies with similar length as 'Apollo 13'\")\n",
    "runtime_results = manhattan_similarity_runtime(metadataDF, apollo_13)\n",
    "runtime_df = display_results(runtime_results, apollo_13, \"runtime (minutes)\")\n",
    "\n",
    "# 4. Levenshtein similarity for title\n",
    "print(\"\\nRequest 4: Show me movies with similar title to 'Fight Club'\")\n",
    "title_results = levenshtein_similarity_title(metadataDF, fight_club)\n",
    "title_df = display_results(title_results, fight_club, \"title\")\n",
    "\n",
    "# 5. Cosine similarity for budget\n",
    "print(\"\\nRequest 5: Show me movies with similar budget to 'The Matrix'\")\n",
    "budget_results = cosine_similarity_budget(metadataDF, matrix)\n",
    "budget_df = display_results(budget_results, matrix, \"budget\")\n",
    "\n",
    "# Store all results for further analysis\n",
    "similarity_results = {\n",
    "    'genre': genre_df,\n",
    "    'revenue': revenue_df,\n",
    "    'runtime': runtime_df,\n",
    "    'title': title_df,\n",
    "    'budget': budget_df\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Study 2: Clustering Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "run_clustering_study() takes 0 positional arguments but 1 was given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 235\u001b[0m\n\u001b[0;32m    232\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mClustering study completed!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 235\u001b[0m     \u001b[43mrun_clustering_study\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetadataDF\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: run_clustering_study() takes 0 positional arguments but 1 was given"
     ]
    }
   ],
   "source": [
    "# Function to perform KMeans clustering\n",
    "def perform_kmeans(data, feature_pairs, k_values):\n",
    "    results = {}\n",
    "    \n",
    "    for features in feature_pairs:\n",
    "        feature_name = f\"{features[0]}_vs_{features[1]}\"\n",
    "        results[feature_name] = {}\n",
    "        \n",
    "        # Extract features\n",
    "        X = data[list(features)].values\n",
    "        \n",
    "        # Standardize features\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "        \n",
    "        for k in k_values:\n",
    "            # Perform KMeans clustering\n",
    "            kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "            clusters = kmeans.fit_predict(X_scaled)\n",
    "            \n",
    "            # Calculate silhouette score if k > 1\n",
    "            if k > 1:\n",
    "                silhouette = silhouette_score(X_scaled, clusters)\n",
    "            else:\n",
    "                silhouette = 0  # Not applicable for k=1\n",
    "            \n",
    "            # Store results\n",
    "            results[feature_name][k] = {\n",
    "                'clusters': clusters,\n",
    "                'centers': scaler.inverse_transform(kmeans.cluster_centers_),\n",
    "                'inertia': kmeans.inertia_,\n",
    "                'silhouette': silhouette\n",
    "            }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Function to perform DBSCAN clustering\n",
    "def perform_dbscan(data, feature_pairs, eps_values, min_samples_values):\n",
    "    results = {}\n",
    "    \n",
    "    for features in feature_pairs:\n",
    "        feature_name = f\"{features[0]}_vs_{features[1]}\"\n",
    "        results[feature_name] = {}\n",
    "        \n",
    "        # Extract features\n",
    "        X = data[list(features)].values\n",
    "        \n",
    "        # Standardize features\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "        \n",
    "        for eps in eps_values:\n",
    "            for min_samples in min_samples_values:\n",
    "                param_key = f\"eps_{eps}_min_samples_{min_samples}\"\n",
    "                \n",
    "                # Perform DBSCAN clustering\n",
    "                dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "                clusters = dbscan.fit_predict(X_scaled)\n",
    "                \n",
    "                # Calculate silhouette score if more than one cluster and no noise points (-1)\n",
    "                unique_clusters = np.unique(clusters)\n",
    "                if len(unique_clusters) > 1 and -1 not in unique_clusters:\n",
    "                    silhouette = silhouette_score(X_scaled, clusters)\n",
    "                else:\n",
    "                    silhouette = 0  # Not applicable\n",
    "                \n",
    "                # Store results\n",
    "                results[feature_name][param_key] = {\n",
    "                    'clusters': clusters,\n",
    "                    'n_clusters': len(np.unique(clusters[clusters >= 0])),\n",
    "                    'n_noise': np.sum(clusters == -1),\n",
    "                    'silhouette': silhouette\n",
    "                }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Function to visualize clustering results\n",
    "def visualize_clustering(data, feature_pairs, kmeans_results, dbscan_results, k_values, eps_values, min_samples_values):\n",
    "    for features in feature_pairs:\n",
    "        feature_name = f\"{features[0]}_vs_{features[1]}\"\n",
    "        x_label = features[0]\n",
    "        y_label = features[1]\n",
    "        \n",
    "        # Create figure for this feature pair\n",
    "        fig = plt.figure(figsize=(20, 10))\n",
    "        \n",
    "        # Plot KMeans results\n",
    "        for i, k in enumerate(k_values):\n",
    "            ax = fig.add_subplot(2, len(k_values) + len(eps_values) * len(min_samples_values), i + 1)\n",
    "            \n",
    "            # Get cluster assignments\n",
    "            clusters = kmeans_results[feature_name][k]['clusters']\n",
    "            centers = kmeans_results[feature_name][k]['centers']\n",
    "            \n",
    "            # Plot data points colored by cluster\n",
    "            scatter = ax.scatter(data[x_label], data[y_label], c=clusters, cmap='viridis', \n",
    "                       alpha=0.5, s=10)\n",
    "            \n",
    "            # Plot cluster centers\n",
    "            ax.scatter(centers[:, 0], centers[:, 1], c='red', marker='X', s=100, label='Centroids')\n",
    "            \n",
    "            ax.set_title(f'KMeans (k={k})\\nInertia: {kmeans_results[feature_name][k][\"inertia\"]:.2f}\\nSilhouette: {kmeans_results[feature_name][k][\"silhouette\"]:.2f}')\n",
    "            ax.set_xlabel(x_label)\n",
    "            ax.set_ylabel(y_label)\n",
    "            ax.legend()\n",
    "            \n",
    "            # Add colorbar\n",
    "            plt.colorbar(scatter, ax=ax, label='Cluster')\n",
    "        \n",
    "        # Plot DBSCAN results\n",
    "        plot_idx = len(k_values) + 1\n",
    "        for eps in eps_values:\n",
    "            for min_samples in min_samples_values:\n",
    "                param_key = f\"eps_{eps}_min_samples_{min_samples}\"\n",
    "                \n",
    "                ax = fig.add_subplot(2, len(k_values) + len(eps_values) * len(min_samples_values), plot_idx)\n",
    "                \n",
    "                # Get cluster assignments\n",
    "                clusters = dbscan_results[feature_name][param_key]['clusters']\n",
    "                \n",
    "                # Plot data points colored by cluster\n",
    "                scatter = ax.scatter(data[x_label], data[y_label], c=clusters, cmap='viridis', \n",
    "                           alpha=0.5, s=10)\n",
    "                \n",
    "                ax.set_title(f'DBSCAN (eps={eps}, min_samples={min_samples})\\nClusters: {dbscan_results[feature_name][param_key][\"n_clusters\"]}\\nNoise: {dbscan_results[feature_name][param_key][\"n_noise\"]}\\nSilhouette: {dbscan_results[feature_name][param_key][\"silhouette\"]:.2f}')\n",
    "                ax.set_xlabel(x_label)\n",
    "                ax.set_ylabel(y_label)\n",
    "                \n",
    "                # Add colorbar\n",
    "                plt.colorbar(scatter, ax=ax, label='Cluster')\n",
    "                \n",
    "                plot_idx += 1\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'clustering_{feature_name}.png', dpi=300)\n",
    "        plt.show()\n",
    "\n",
    "# Function to analyze cluster metrics\n",
    "def analyze_clusters(data, feature_pairs, kmeans_results, dbscan_results, k_values, eps_values, min_samples_values):\n",
    "    for features in feature_pairs:\n",
    "        feature_name = f\"{features[0]}_vs_{features[1]}\"\n",
    "        print(f\"\\n=== Cluster Analysis for {feature_name} ===\")\n",
    "        \n",
    "        # Analyze KMeans clusters\n",
    "        print(\"\\nKMeans Clusters:\")\n",
    "        for k in k_values:\n",
    "            clusters = kmeans_results[feature_name][k]['clusters']\n",
    "            \n",
    "            # Calculate cluster cardinality (number of points in each cluster)\n",
    "            cardinality = np.bincount(clusters + 1)  # +1 to handle -1 cluster\n",
    "            \n",
    "            # Calculate cluster magnitude (average distance to centroid)\n",
    "            X = data[list(features)].values\n",
    "            scaler = StandardScaler()\n",
    "            X_scaled = scaler.fit_transform(X)\n",
    "            \n",
    "            centers = kmeans_results[feature_name][k]['centers']\n",
    "            centers_scaled = scaler.transform(centers)\n",
    "            \n",
    "            magnitudes = []\n",
    "            for i in range(k):\n",
    "                cluster_points = X_scaled[clusters == i]\n",
    "                if len(cluster_points) > 0:\n",
    "                    center = centers_scaled[i]\n",
    "                    distances = np.sqrt(np.sum((cluster_points - center) ** 2, axis=1))\n",
    "                    magnitude = np.mean(distances)\n",
    "                    magnitudes.append(magnitude)\n",
    "                else:\n",
    "                    magnitudes.append(0)\n",
    "            \n",
    "            print(f\"  k={k}:\")\n",
    "            print(f\"    Inertia: {kmeans_results[feature_name][k]['inertia']:.2f}\")\n",
    "            print(f\"    Silhouette Score: {kmeans_results[feature_name][k]['silhouette']:.2f}\")\n",
    "            print(f\"    Cluster Cardinality: {cardinality}\")\n",
    "            print(f\"    Cluster Magnitude: {magnitudes}\")\n",
    "        \n",
    "        # Analyze DBSCAN clusters\n",
    "        print(\"\\nDBSCAN Clusters:\")\n",
    "        for eps in eps_values:\n",
    "            for min_samples in min_samples_values:\n",
    "                param_key = f\"eps_{eps}_min_samples_{min_samples}\"\n",
    "                clusters = dbscan_results[feature_name][param_key]['clusters']\n",
    "                \n",
    "                # Calculate cluster cardinality (number of points in each cluster)\n",
    "                unique_clusters = np.unique(clusters)\n",
    "                cardinality = {c: np.sum(clusters == c) for c in unique_clusters}\n",
    "                \n",
    "                print(f\"  eps={eps}, min_samples={min_samples}:\")\n",
    "                print(f\"    Number of Clusters: {dbscan_results[feature_name][param_key]['n_clusters']}\")\n",
    "                print(f\"    Number of Noise Points: {dbscan_results[feature_name][param_key]['n_noise']}\")\n",
    "                print(f\"    Silhouette Score: {dbscan_results[feature_name][param_key]['silhouette']:.2f}\")\n",
    "                print(f\"    Cluster Cardinality: {cardinality}\")\n",
    "\n",
    "# Main function to run the clustering study\n",
    "def run_clustering_study(metadataDF):\n",
    "    movie_data = metadataDF.copy()\n",
    "    metadataDF = metadataDF[(metadataDF['budget'] > 0) & (metadataDF['revenue'] > 0)]\n",
    "    \n",
    "    # Log transform budget and revenue (they're highly skewed)\n",
    "    metadataDF['log_budget'] = np.log1p(metadataDF['budget'])\n",
    "    metadataDF['log_revenue'] = np.log1p(metadataDF['revenue'])\n",
    "    print(f\"Loaded {len(movie_data)} movies.\")\n",
    "    \n",
    "    # Define feature pairs to analyze\n",
    "    feature_pairs = [\n",
    "        ('log_budget', 'log_revenue'),  # Budget vs Revenue\n",
    "        ('runtime', 'log_budget')       # Runtime vs Budget\n",
    "    ]\n",
    "    \n",
    "    # Define parameters to test\n",
    "    k_values = [3, 5]                   # Number of clusters for KMeans\n",
    "    eps_values = [0.5, 1.0]             # Epsilon values for DBSCAN\n",
    "    min_samples_values = [5, 10]        # Minimum samples for DBSCAN\n",
    "    \n",
    "    # Perform clustering\n",
    "    print(\"\\nPerforming KMeans clustering...\")\n",
    "    kmeans_results = perform_kmeans(movie_data, feature_pairs, k_values)\n",
    "    \n",
    "    print(\"\\nPerforming DBSCAN clustering...\")\n",
    "    dbscan_results = perform_dbscan(movie_data, feature_pairs, eps_values, min_samples_values)\n",
    "    \n",
    "    # Visualize results\n",
    "    print(\"\\nVisualizing clustering results...\")\n",
    "    visualize_clustering(movie_data, feature_pairs, kmeans_results, dbscan_results, \n",
    "                        k_values, eps_values, min_samples_values)\n",
    "    \n",
    "    # Analyze cluster metrics\n",
    "    print(\"\\nAnalyzing cluster metrics...\")\n",
    "    analyze_clusters(movie_data, feature_pairs, kmeans_results, dbscan_results,\n",
    "                   k_values, eps_values, min_samples_values)\n",
    "    \n",
    "    print(\"\\nClustering study completed!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_clustering_study(metadataDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References:\n",
    "- Clustering Algorithm KBmeans: https://www.w3schools.com/python/python_ml_k-means.asp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
